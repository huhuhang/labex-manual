# How to Start

## Prerequisites

To author interactive labs and challenges, you must already be familiar with the following:

- Using the Linux command-line interface (Specifically, a bash terminal).
- [Git and GitHub](https://docs.github.com/en/get-started/using-git/about-git) (Cloning a repository, making commits, and pushing commits to a server).
- [Markdown](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax) (Writing text and basic formatting syntax).
- JSON (Config file format).

Of course, you'll also need expertise in the subject matter of your labs.

## Basic Structure

We have created a GitHub repository that contains multiple folders, with one folder for each Lab.

[**↗ View Storage Structure**](https://github.com/labex-labs/scenarios)

```
repo-name
├── linux
│   ├── lab-name-1
│   ├── lab-name-2
│   └── lab-name-3
```

`linux` is the direction name and `lab-name-1` is the lab/challenge name. Names are all lowercase, using hyphens to separate words.

Each folder already includes all the essential elements for a lab/challenge.

Look inside the folder:

```
├── basic-template
│   ├── assets
│   │   └── example-asset.md
│   ├── finish.md
│   ├── index.json
│   ├── intro.md
│   ├── setup.sh
│   ├── solutions
│   │   └── solution-asset.md
│   ├── step1.md
│   ├── step2.md
│   ├── verify1-1.sh
│   ├── verify1-2.sh
│   └── verify2.sh
```

Note:

- `index.json`: the config file for your scenario, including where you specify the title, description, level, and estimated time to complete, as shown to learners.
- `intro.md` and `finish.md`: Markdown files for the text shown at the start and end of the Lab.
- `step*.md`: Markdown files for the lesson text are shown alongside each "step" of the Lab.
- `setup.sh`: a shell script executed at the lab environment starting. The execution process and results are not visible to the user, and do not write commands that take a long time to execute.
- `verify*.sh`: Shell scripts executed to verify the steps are complete. One step can have single or multiple verification scripts.
- `assets`: (Optional) the folder includes all the example data or supporting files used in the Lab. Images of the markdown files should be [compressed](https://tinypng.com/) to reduce the size of the repository.
- `solutions`: (Optional) the folder includes all the solution files of challenges. The lab will not include the solution files.

Most of the configuration items in the `index.json` file are already written, you can use the [LabEx CLI](https://github.com/labex-labs/labex-cli) to initialize a blank lab/challenge and then modify it.

## Step Content

The `step*.md` file is the content of the step. The content of the step is written in Markdown format. The content of the step can be divided into two parts: the text part and the code part.

Some notes:

- A single step should contain the content of only [One Main Skill Point](skill-tree).
- Long content should be broken down into smaller steps.
- The steps should include code exercises. The theoretical explanation should be integrated into the process of code practice.

## index.json Configuration

This is a sample `index.json` file:

```json copy
{
  "type": "lab",
  "title": "Basic Template",
  "description": "The description of basic template",
  "difficulty": "Beginner",
  "time": 5,
  "details": {
    "steps": [
      {
        "title": "Bananas",
        "text": "step1.md",
        "verify": [
          {
            "name": "Check if bananas.txt exists",
            "file": "verify1-1.sh",
            "hint": "Please create file bananas.txt in /home/labex",
            "timeout": 0,
            "showstderr": false
          },
          {
            "name": "Check if apples.txt exists",
            "file": "verify1-2.sh",
            "hint": "Please create apples.txt in /home/labex",
            "timeout": 10,
            "showstderr": true
          }
        ],
        "skills": ["linux/ls", "linux/cd"],
        "layout": "doc-workbench-split"
      },
      {
        "title": "Oranges",
        "text": "step2.md",
        "verify": [
          {
            "name": "Check if oranges.txt exists",
            "file": "verify2.sh",
            "hint": "Please create file test.txt in /home/labex",
            "timeout": 0,
            "showstderr": false
          }
        ],
        "skills": ["linux/ls", "linux/cd"]
      }
    ],
    "intro": {
      "text": "intro.md",
      "background": "setup.sh"
    },
    "finish": {
      "text": "finish.md"
    },
    "assets": {
      "host01": [
        {
          "file": "*",
          "target": "~/"
        }
      ]
    }
  },
  "backend": {
    "imageid": "vnc-ubuntu:2004"
  }
}
```

![A sample index.json](.github/assets/index-json.png)

The fields in `index.json` are explained in detail.

### Basic fields

```json copy
{
  "type": "lab",
  "title": "Basic Template",
  "description": "The description of basic template",
  "difficulty": "Beginner",
  "time": 5
}
```

There are five basic fields in `index.json`:

1. `type`: The type of scenario must be `lab` or `challenge`. [See more details](labs-and-challenges)
2. `title`: The title of the scenario. Usually, the title is the same as the folder name.
3. `description`: The description of the scenario, usually, 10 to 30 characters.
4. `time`: Estimated completion time in minutes, usually in multiples of 5.
5. `difficulty`: The difficulty of scenario must be `Beginner`, `Intermediate` or `Advanced`.

The difficulty can be one of the following:

- `Beginner`: The Lab/Challenge contains only single or multiple skills **in the same skills group**.
- `Intermediate`: The Lab/Challenge contains multiple skills from **different skill groups**. and the skills are not very difficult.
- `Advanced`: The Lab/Challenge contains multiple skills from **different subjects or projects**. and the skills are more difficult.

_Our skills structure: `Skill` > `Skill Group` > `Subject` > `Project`. e.g: `cd` > `Directory Operations` > `Linux Commands` > `Linux`_

[**↗ About Skill Tree**](skill-tree)

### Details fields

Details fields are the most important fields in `index.json`. The `details` field contains the following items:

#### Steps

The `intro` and `finish` items are the configuration of the start and end of the Lab. Both are special steps, and default to `doc-fullscreen` layout.

```json copy
"intro": {
  "text": "intro.md",
  "background": "setup.sh"
},
"finish": {
  "text": "finish.md"
}
```

If `setup.sh` is specified in the `background` item, the script will be executed when the Lab starts.

Other `steps` item specifies the steps of the lab.

```json copy
"steps": [
  {
    "title": "Bananas",
    "text": "step1.md",
    "verify": [
      {
        "name": "Check if bananas.txt exists",
        "file": "verify1-1.sh",
        "hint": "Please create file bananas.txt in /home/labex",
        "timeout": 0,
        "showstderr": false
      },
      {
        "name": "Check if apples.txt exists",
        "file": "verify1-2.sh",
        "hint": "Please create apples.txt in /home/labex",
        "timeout": 10,
        "showstderr": true
      }
    ],
    "skills": ["linux/ls", "linux/cd"],
    "layout": "doc-workbench-split"
  }
]
```

The parameters of the steps are:

1. `title`: The title of the step. It will be displayed to the learner, so it should be clear and concise.
2. `text`: The markdown file of the step. The name of the markdown file.
3. `verify`: The `verify` parameter contains a series of verification scripts that will be executed **in order**. The parameters of the verification scripts are:
   1. `name`: The purpose of the script. It will be displayed to the learner, so it should be clear and concise.
   2. `file`: The name of the script.
   3. `hint`: The message when the script is unsuccessful will be displayed to the learner, so it should be clear and concise.
   4. `timeout`: Default `0`, which means no limit on the execution time of the script, if set, it means a limit on the number of seconds to execute.
   5. `showstderr`: Default is `false`, set to true to show stderr returned by the script, and no longer displays hint.
4. `skills`: The skills of the step. it comes from the official skills tree. [See more details](skill-tree).
5. `layout`: (Optional) The layout of the step, must be `doc-workbench-split` or `doc-fullscreen`. Intro and finish step default to `doc-fullscreen`, other steps default to `doc-workbench-split` if not filled.

The verification script is executed when the learner completes a step and clicks the `Next` button.

It runs in the background until it returns an exit code of zero (success), at which point the step is flagged as completed, and the lab proceeds to display the next step.

No parameters are passed to the verification script, and the script is expected to return the standard zero for success or non-zero for failure.

##### verify.sh

The Verify step detection script is one of LabEx's important features, and the system can automatically detect every step of the user's operations. You can simply understand the Verify detection script as a unit test of user code.

1. In challenges, the Verify detection script needs to be very rigorous and can correctly determine whether the user has done it right or wrong. Only the correct answer can pass, while the wrong answer will report an error and throw a prompt.
2. In labs, the Verify detection script can be relaxed appropriately, usually keyword detection to see if the relevant operations have been completed. Labs do not need to spend as much time debugging the Verify script as challenges, and the detection in labs is to give users a sense of interactive learning. It is important for the system to provide feedback to users when they learn on the computer.

**The verification process is roughly as follows:**

1. The user completes the corresponding operation in the environment based on the content description.
2. The user clicks the next step, and the background detection script is triggered automatically and executed one by one (the execution process is invisible to the user, and the execution error results can be configured by `showstderr` whether visible to the user).
3. The script execution process is the system **connecting to the user environment through SSH and executing it in the environment with default user permissions**. The detection script is a Bash command.
4. An execution error will be thrown when there is an error, and it will pass when all executions are completed.

The foundation of Verify script is Shell command, because it needs to be connected to the user environment through SSH to execute, but the content of execution can be customized, and the flexibility is very high:

1. Taking Python as an example, we can use unittest to write complete unit tests for user code, and then execute the unit tests in the Verify script. This means that the user's code detection is done by Python unit test code, and the Shell script only triggers the execution of the unit test.
2. Similar to Python, Junit is recommended for Java unit testing, and third-party tools can be used for front-end automation testing.
3. Database: You can use a proficient programming language to connect to the database to access data for judgment. You can also use database logs for detection.
4. API/HTTP requests: Use curl or proficient programming language to build HTTP requests.

**Principles of accurate detection:**

Use a confusion matrix to represent the correctness of the user's answer and the correctness of the detection judgment.

![matrix](.github/assets/matrix.png)

When writing the Verify script, **efforts should be made to reduce FP and FN. It is better to have FP than FN.**

#### Assets

The `assets` item specifies which assets you want to be copied to the lab environment at runtime. The default name of your lab environment is `host01`, and you can copy all files to the home folder of the default login user.

```json copy
"assets": {
    "host01": [
        { "file": "*", "target": "~/" }
    ]
}
```

Note that the target directory can be anything you want. In this example, `~/` maps to `/home/labex`, since `labex` is the default user, and `/home/labex` is that user's home directory.

The example below copies over three specific assets. Instead of using the `*` wildcard to select all assets, two files are copied into the home directory, while a third is copied into `/usr/local/bin`, and its permissions are set to executable.

```json copy
"assets": {
    "host01": [
        {"file": "sample_code.py", "target": "~/" },
        {"file": "sample_data.csv", "target": "~/" },
        {"file": "sneaky_script.sh", "target": "/usr/local/bin/", "chmod": "+x"}
    ]
}
```

Keep your assets lightweight; each is limited to 9 MB per file. There is no limit to the number of assets, but using more assets will increase the loading time of the Lab.

## Backend Configuration

`Backend` is the environment configuration for experiments and challenges, and must be an official name provided. Currently supported environments include:

- `vnc-ubuntu:2204`
- `webide-ubuntu:2204`
- `vnc-instance-ubuntu:2204`
- `webide-instance-ubuntu:2204`

Environment explanations are as follows:

1.  `vnc` refers to an environment that defaults to a GUI desktop after startup, and `webide` refers to an environment that defaults to VS Code after startup. The two are essentially the same, with only different default views after startup.
2.  `instance` refers to a new virtual machine instance (cloud host) after startup, and does not include `instance` which refers to a new container instance (Docker).
3.  `ubuntu:2204` refers to the operating system being Ubuntu 22.04 after startup, and currently only Ubuntu 22.04 is supported.

The recommended selections are as follows:

1.  If the experiment/challenge requires a GUI environment, or **will not involve a lot of code file editing operations** (writing a lot of code in VNC has a poor experience), it is recommended to use the `vnc` desktop environment.
2.  If the experiment/challenge does not require a GUI environment, or **will involve a lot of code file editing operations**, it is recommended to use the `webide` code editor environment.
3.  In most cases, the default is to use a non-cloud host environment, that is, without `instance`, because the startup time of the cloud host environment is longer and the cost of the cloud host environment is high, which is not suitable for a large number of experiments/challenges.
4.  If the experiment/challenge does not support running in a container environment, or requires using the `instance` cloud host environment. For example, Docker-related experiments/challenges cannot be completed in a Docker container environment and require a cloud host.
